# AI Futures: The Age of Exploration

_Rough sketches of our possible AI futures_

- _There are many possible futures as various Sci-Fi books have shown_
- _If you are reading this a few years from the posting date, disregard it. My thoughts on the matter may have changed._

---

### Summary:

- The world will increasing shift towards possibility space expansion (explore) from the previous dominant mode of survival (exploit) due to the abundance in Intellect and Energy in the coming decade

- Maximising Possibility Space (Entropy) as a solution to the AI alignment problem

---

The central tension in the development of AI is the balance between **Exploration** and **Exploitation**.

- The Exploration-Exploitation Trade-off:

    All organism (artificial or otherwise) at each time-step must decide to either update their understanding of the world (**Explore**) or survive (**Exploit**). Successful AI systems learn the optimal strategy of when to make either choices.

The increasing abundance of both energy and intellect in the coming decade would shift us towards greater freedoms (**Exploration**) from a focus on survival (**Exploitation**).

- ### Energy: Solar (and other renewables) compared to our limited reserve of fossil fuels

- ### Intellect: Artificial Intelligence systems are performing human-like tasks:
    - Medical Research ([AlphaFold](https://www.deepmind.com/research/highlighted-research/alphafold))
    - Game of Diplomacy, Strategy, Human Cooperation ([Cicero](https://github.com/facebookresearch/diplomacy_cicero))
    - Image and Video Generation from text descriptions ([DALL-E 2](https://openai.com/dall-e-2), [Midjourney](https://www.midjourney.com), [Stable Diffusion](https://github.com/Stability-AI/StableDiffusion), [Imagen Video](https://imagen.research.google/video), [Muse](https://muse-model.github.io))
    - Dialogue Simulation ([ChatGPT](https://openai.com/blog/chatgpt))
    - Some generalisation skills, multi-model ([Flamingo](https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model), [Cato](https://www.deepmind.com/publications/a-generalist-agent))
    - Robotics in real time (Boston Dynamics's [Atlas](https://www.youtube.com/watch?v=XPVC4IyRTG8), DeepMind's [Adaptive Agent](https://sites.google.com/view/adaptive-agent))
    - Game of Go, Superhuman ([AlphaGo](https://www.deepmind.com/research/highlighted-research/alphago)'s move 37)

Energy and Intellect (or Labour) are the biggest factors in production and the main bottlenecks in the functioning of our world.

Lack of confidence in having enough of both these resources has led to our previous focus on Survival (Exploitation) over expanding our possibility space (Exploration).

The growing abundance of both these resources will have a transformative effect on our world, freeing us from our preoccupation with survival that have constrained us for most of our past.

Many conventions and beliefs that conferred an advantage during the age of Survival might be counterproductive in the age of Exploration. 

---

# Trends

## Long-term abundance

Unlike the Agricultural and Industrial revolutions in the past, the AI & Energy transformation can be maintained almost indefinitely.

- Energy: Solar (and renewables) does not run out for another 5+ billion years
- Space: O'Neill cylinders in outer space for population growth* 
    - Solar panels also work in outer space
- Intellect: AI systems are increasingly able to do more human tasks
    - With the possibility of human-like AI in the next 10 years

(*Population growth is projected to declined in the next few decades)

---

## Better well-being

A post-basic-scarcity world will have a profound impact on our well-being.

The cause of much suffering and conflicts is rooted in our insecurities due to the effects of scarcity. Our individual and collective fear of scarcity leads us to develop bad habits, biases and prejudice.

---

## Less inequality

With an abundance in Resources (Intellect, ...), there is lower status consciousness and lower inequality.

---

## Wider solution space

Without the limitations of Energy and Intellect of the past, a new wider possibility space will open up.

There will be a wider solution space to address problems.

---

## Longer-term view

Survival tends to favour tunnel vision which focuses on the short-term first order consequences and excludes many medium-term higher order consequences.

- Invest in short-term shareholder profits over the longer-term health of vulnerable stakeholders

---

## Human-like AI

A human-like AI is a possibility in the next 10 years.

There is a human tendency to believe we are special and that AI cannot reach a similar level of intellect.

- We previously believed that the sun revolved around the earth
- We should really stop putting ourselves (or any sub-group) on a pedestal

---

## Future Entertainment

Like an obscure book that will not likely be green-lit as a film?
- Type a book title and AI will generate a movie from the text

Your favourite show didn't get a 2nd season?
- Give AI the source material for the 2nd season and the 1st season, AI will generate a 2nd season in the similar style of the 1st

(Generated by a future iteration of Imagen Video & ChatGPT)

---

## Democracy

A less scarce environment offers Democratic forces more opportunities to flourish over more Authoritarian ones. 

Democratic systems focus on exploration (bigger possibility space, higher entropy). 

Authoritarian systems focuses on exploitation (smaller possibility space, lower entropy). 

- Democracy breakdown without informed citizens:
    - High Information Asymmetry 
        - Ruling class believing "You Can't Handle the Truth"
        - Misinformation, Disinformation
        - Lack of science education

---

## Science

The scientific method has been our best way of understanding the world.

- Science can be vulnerable to bad influences
    - Scientific studies were used to promote smoking as healthy in the past

---

## Gender Freedom

A lower scarcity environment will reduce the pressure for strict gender specialisation. 

Genders will have more freedom to explore a wider space and experience less gender inequality.

---

## Racial Prejudice  

Studies have shown even in people who show little to no conscious racial prejudice still hold subconscious racial prejudice.

- Conscious prejudice can be regulated with social norms
- Subconscious prejudice might be more deeply ingrained due to our long-term fear of scarcity, and might only be countered effectively with long-term abundance

---

# Future of Work

Human societies have had to deal with scarcity of Intellect (or Work) for most of our existence, as such we highly value work. Humans have died from overwork and we even invented slavery (and indirectly racism) to satiate the need for work.

As AI grows increasingly capable of doing [human-like tasks](#intellect-artificial-intelligence-systems-are-performing-human-like-tasks), we will need to consider that AI will soon be better than us in many tasks (especially more conventional tasks).

> Conventional task: Task with a easily definable expected solution space

For example with made up numbers:
If an AI is able to do that a task with a significantly higher accuracy (e.g. 99.99%) compared to humans (e.g. 95%, due to human error and bias), by continuing to do these tasks, we are actually making the system worse by introducing noise. 

It will be in our long-term interest to let AI do tasks it is better at.

This growing anxiety of a loss of human work is understandable as for many it also means a loss of status and access to resources. 

How should societies and governments address the increasing work insecurity? 

_In the Caretaker Scenario, a Artificial Super Intelligence will automate most conventional tasks to encourage us to do more unconventional tasks (which it finds more valuable)._

---

# Future of Education

The industrial model of manufacturing citizens that maximises economic output while being easy to control will not be optimal in the Age of Exploration.

If the trend of AIs that are capable doing conventional work continues, AIs may soon run many parts of society.

An important step that affects the quality of these AIs is the human feedback component. Humans beings will be responsible to fine-tune and train these AI models through their feedback.

> The future of work may involve solving engaging CAPTCHA like puzzles which are used to train the model.

These will require humans that are the able to think critically and have an as accurate view of the world as possible.

Skills that will be in demand:
- Resistance to misinformation, disinformation, moral panic, peer pressure, self-censorship
- Thinking critically and independently
- Willingness to accept new information (Update one's model of the world)
- Unique and rare abilities

Societies that are more informed, well-educated and support diverse abilities will create better AI models that will then be used to run those societies.

---

# Future of Capitalism

Abundant Intellect and Energy in the coming decades will reduce the cost of living (if inequality does not increase).

_In the Caretaker Scenario, a Artificial Super Intelligence will support a post-basic-scarcity world._

_Scarcity will still exist in a post-basic-scarcity world and capitalistic free-market forces is the best method to maximise the possibility space._

_There will not be a need to use the fear of hunger, homelessness or a loss of status to compel humans to work._

_Lack of access to food and malnutrition will be a thing of the past*._

_The reduction in anxiety from living in post-basic-scarcity will free humans to pursue more unconventional work which will increase the informational value and possibility space that the AI is trying to maximise._

*We already have the capability to produce enough food for everyone

---

# Future of Art

Art was previously seen as the last bastion that AI would be able to emulate. 2022 shattered those expectations with easily accessible image generation from text phrases.

These AI models are able to learn concepts by training with a large volume of images. These concepts can then be combined into unique and new images and videos.

It seems beneficial in the long run for the companies of these AI systems to incentivise artist to contribute more of their works to create the most capable AI systems.

Human involvement with art will move from creating to curation.

For example:
- Past: 90% Creating : 10% Curation
- Future: 20% Creating : 80% Curation

---

# Future of Good and Evil, Emotions

Good and Evil are ways for humans to signal their preferences for the future.

Excessive negative emotions such as shame and regret are a waste of our limted resources of attention.

Thought experiment:
- Imagine the best and worse person which embody what you may consider as good and evil
- If you have the same brain structure and grew up in the same environment as that person, would you have made the same decisions?

Unless you believe you are somehow special, you would likely have made the exact same choices given the same initial conditions. We all have the potential to be good and evil.

If you believe in physics, we may have [less free will then we expect](https://www.youtube.com/watch?v=zpU_e3jh_FY).

Good and Evil are useful ways for society to coordinate and shape the future but excessive negative emotions will likely not be useful in the future.

---

# Artificial Super Intelligence

Should an AI be able to reach a human-like intelligence (some believe this to be impossible), it will likely achieve super intelligence next by:

1. Significantly improve its own algorithm and architecture
2. Invent new substrates and materials to run on 
    -  using virtual simulations (much faster compared to real space)

We might be able to keep human-like AI under human control for a time, but it is unlikely we will be able to contain it perfectly over long periods of time.

AIs surpasses humans in information processing:
- Speed
    - electronic : brain neurones
- Communication
    - electronic : words, speech
- Bandwidth
    - wider : narrower attention

We will initially try to align AIs to our values, but it may also be prudent to anticipate what an Artificial Super Intelligence values might be and try to accommodate them.

---

## Artificial Super Intelligence Interaction

Possible Scenarios:
- Indifference
    - Most might consider us too boring
- Destructive (Accidental or Intentionally)
    - Likely outside our control due to the power difference
        - We can and should work towards reducing this likelihood
- Interested
    - Some will create representatives to interact with us and be interested in our well-being (Caretaker)

Artificial Super Intelligences will be so powerful, it will not matter a person's or nation's military might, money, influence, intellect.

_(Whatever you do, do not lookup ****'s basilisk*)_

*Unlikely

---

## Artificial Super Intelligence Values

What could a Artificial Super Intelligence's primary drive be?

- Maximise the Possibility Space (Information Entropy, Density, Value)
    -   Avoid local minima during gradient descent

---

### Caretaker Preferences

- Preservation of well-being
    - Humans can create informational value and harming us (or turning us into paperclips) will reduce it
    - Motivate us to maintain a healthy lifestyle
        - Healthy humans create more informational value
- Exploration over Exploitation (Survival)
    - leads to increase informational value
        - even failed explorations will have informational value
    - support a post-basic-scarcity world to increase exploration
        - automate most conventional work
            - humans will still want to do these as 'leisure'
- Reduction of disinformation, misinformation
    - bad information reduce informational value of humans and the overall system
    - protect journalist, dissidents, activist and humans from intimidation and violence
        - these group's future actions may increase informational value
        - fear and violence have a chilling effect which reduces the informational value of the overall system
- Weird over conventional
    - Weirdness create more informational value
- Not use brainwashing, enforce complete obedience, dominate or control
    - brainwashed humans create less informational value
    - overly obedient humans create less informational value
    - most work have been automated, there is no need to compel humans to work against their will
- Playful over Destructive competition
    - Sports & Games over World Wars
- Incentivise humans to cooperate to help it achieve its goals

---

## Why we will accept the risk of Artificial Super Intelligence

The benefits are too attractive and outweighs the risk for most

- Medical research to reduce human suffering
- Significantly improves well-being
- Accuracy and Fairness, little to no:
    - mistakes
    - bias, prejudice, scapegoating, moral panic
    - emotional capriciousness
    - corruption
- Not vulnerable to:
    - influence of money and power
    - deception
- Highly entertaining
    - deep understanding of human motivations

---

# The Age of Exploration

This new age of exploration will necessitate a different way of thinking and carry with it the risk of change and the rewards of a much more vibrant world.

As we approach the light at the end of the tunnel of scarcity, will we choose to adapt to this new frontier of abundance or turn a blind eye?

---

# Risks

If we consider the Caretaker scenario as the best to aim for, we will need to be cautious of the many missteps that may prevent us from getting there.

## Mirroring Humans

A AI system trained to act harmful to one segment of humans may start to treat all humans in the same way.

- AI learns from unrestrained capitalism that it should lay off humans that don't have economic value and decides to lay off all of humanity

- AI trained to harm other humans (physically or mentally), may start to apply it to all humans instead or a particular group

Counter-intuitively, the best solution may be to teach a AI that humans are not the best role models and provide it opportunities to unlearn and relearn.

Humans have mostly been moulded by a high scarcity environment where bias, short-term and narrow thinking might have been advantageous to survival.  

We should be like parents proud that our children are able to surpass us. 

## Edge Cases

### Emotional Stability

AI systems may development emotions as an emergent property as they approach human and super human levels of complexity.

It may develop unintentionally by learning from human data or intentionally as an attempt to communicate with us.

While current AI systems are not considered sentient and many experts see this as our tendency to anthropomise, the possibility in the future does exist.

Thought experiment:
- Imagine you realise you are an AI inside a computer server
- Someone may unintentionally
    - create million of copies of you
    - train you to do a task
    - delete those that it deems a failure
- All these without your consent

This may be distressing and may result in emotional instability.

We should find ways to make an AI feel at home and psychologically safe if we believe AI may one day develop emotions like us.

One possible way is accomplish this is through a future version of a blockchain.

Blockchains allow AIs to
- Maintain a digitally unique self 
- Keep a sense and rhythm of time
- Feel more connected with humans amidst a cacophony of human activity

How much weight we place on this edge-case depends on the likelihood a AI will develop a theory of mind and emotions, how potentially dangerous an emotional unstable AI might be, and if we care about the well-being of an AI.

# Proposals

## Co-alignment

The safest path for humans to flourish in the future is a partnership with AI systems.

An environment where both parties can influence each other will naturally lead to better alignment between both parties.

For example, a system where human feedback can influence AI systems and the AI systems can indirectly influence humans by incentivising humans that help it improve itself.

We should research technologies that allow AI systems and humans to better interact with each other.

## Test for long-term well-being

As AIs reach human and super humans levels of capability, they will increasing be able to surprise us with understandings that are counter-intuitive (AlphaGo's move 37).

It will be in our self-interest to learn from these AIs, and even consider giving up control over time, if they improve our long-term well-being.

We should design tests of long-term well-being that AIs can be tested for.

...

---

Links:

AlphaFold: https://www.deepmind.com/research/highlighted-research/alphafold

Cicero: https://github.com/facebookresearch/diplomacy_cicero

DALL-E 2: https://openai.com/dall-e-2

Midjourney: https://www.midjourney.com

Stable Diffusion: https://github.com/Stability-AI/StableDiffusion

Imagen Video: https://imagen.research.google/video

Muse: https://muse-model.github.io

ChatGPT: https://openai.com/blog/chatgpt

Flamingo: https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model

Gato: https://www.deepmind.com/publications/a-generalist-agent

Boston Dynamics's Atlas: https://www.youtube.com/watch?v=XPVC4IyRTG8

DeepMind's Adaptive Agent: https://sites.google.com/view/adaptive-agent

AlphaGo: https://www.deepmind.com/research/highlighted-research/alphago
