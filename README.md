# AI Futures: The Age of Exploration

_Rough sketches of our possible AI futures_

- _There are many possible futures as various Sci-Fi books have shown_
- _If you are reading this a few years from the posting date, disregard it. My thoughts on the matter may have changed._

---

### Summary:

- Maximising information entropy (and protecting against information entropy reduction) as a solution to the AI alignment problem

- The world will increasing shift towards possibility space expansion (explore) from the previous dominant mode of survival (exploit) due to the abundance in Intellect and Energy in the coming decade

---

The central tension in the development of AI is the balance between **Exploration** and **Exploitation**.

- The Exploration-Exploitation Trade-off:

    All organism (artificial or otherwise) at each time-step must decide to either update our understanding of the world (**Explore**) or survive (**Exploit**). Successful AI systems learn the optimal strategy of when to make either choices.

The increasing abundance of both energy and intellect in the coming decade would shift us towards greater freedoms (**Exploration**) from a focus on survival (**Exploitation**).

- ### Energy: Solar (and other renewables) compared to our limited reserve of fossil fuels

- ### Intellect: Artificial Intelligence systems are performing human-like tasks:
    - Medical Research (Alphafold)
    - Game of Diplomacy, Strategy, Human Cooperation (Cicero)
    - Image and Video Generation from text descriptions (DALL-E 2, Midjourney, Stable Diffusion, Imagen Video, Muse)
    - Some generalisation skills, multi-model (Flamingo, Cato)

Energy and Intellect (or Labour) are the biggest factors in production and the main bottlenecks in the functioning of our world.

Lack of confidence in having enough of both these resources has led to our previous focus on Survival (Exploitation) over expanding our possibility space (Exploration).

The growing abundance of both these resources will have a transformative effect on our world, freeing us from our preoccupation with survival that have constrained us for most of our past.

Many conventions and beliefs that conferred an advantage during the age of Survival might be counterproductive in the age of Exploration. 

---

# Trends

## Long-term abundance

Unlike the Agricultural and Industrial revolutions in the past, the AI & Energy transformation can be maintained almost indefinitely.

- Energy: Solar (and renewables) does not run out for another 5+ billion years
- Space: O'Neill cylinders in outer space for population growth* 
    - Solar panels also work in outer space
- Intellect: AI systems are increasingly able to do more human tasks
    - With the possibility of human-like AI in the next 10 years

(*Population growth is projected to declined in the next few decades)

---

## Better well-being

A post-basic-scarcity world will have a profound impact on our well-being.

The cause of much suffering and conflicts is rooted in our insecurities due to the effects of scarcity. Our individual and collective fear of scarcity leads us to develop bad habits, biases and prejudice.

---

## Less inequality

With an abundance in Resources (Intellect, ...), there is lower status consciousness and lower inequality.

---

## Wider solution space

Without the limitations of Energy and Intellect of the past, a new wider possibility space will open up.

There will be a wider solution space to address problems.

---

## Longer-term view

Survival tends to favour tunnel vision which focuses on the short-term first order consequences and excludes many medium-term higher order consequences.

- Invest in short-term shareholder profits over the longer-term health of vulnerable stakeholders

---

## Human-like AI

A human-like AI is a possibility in the next 10 years.

There is a human tendency to believe we are special and that AI cannot reach a similar level of intellect.

- We previously believed that the sun revolved around the earth
- We should really stop putting ourselves (or any sub-group) on a pedestal

---

## Future Entertainment

Like an obscure book that will not likely be green-lit as a film?
- Type a book title and AI will generate a movie from the text

Your favourite show didn't get a 2nd season?
- Give AI the source material for the 2nd season and the 1st season, AI will generate a 2nd season in the similar style of the 1st

(Generated by a future iteration of Imagen Video & ChatGPT)

---

## Democracy

A less scarce environment offers Democratic forces more opportunities to flourish over more Authoritarian ones. 

Democratic systems focus on exploration (bigger possibility space, higher entropy). 

Authoritarian systems focuses on exploitation (smaller possibility space, lower entropy). 

- Democracy breakdown without informed citizens:
    - High Information Asymmetry 
        - Ruling class believing "You Can't Handle the Truth"
        - Misinformation, Disinformation
        - Lack of science education

---

## Science

The scientific method has been our best way of understanding the world.

- Science can be vulnerable to bad influences
    - Scientific studies were used to promote smoking as healthy in the past

---

## Gender Freedom

A lower scarcity environment will reduce the pressure for strict gender specialisation. 

Genders will have more freedom to explore a wider space and experience less gender inequality.

---

## Racial Prejudice  

Studies have shown even in people who show little to no conscious racial prejudice still hold subconscious racial prejudice.

- Conscious prejudice can be regulated with social norms
- Subconscious prejudice might be more deeply ingrained due to our long-term fear of scarcity, and might only be countered effectively with long-term abundance

---

# Future of Work

Human societies have had to deal with scarcity of Intellect (or Work) for most of our existence, as such we highly value work. Humans have died from overwork and we even invented slavery (and indirectly racism) to satiate the need for work.

As AI grows increasingly capable of doing [human-like tasks](#intellect-artificial-intelligence-systems-are-performing-human-like-tasks), we will need to consider that AI will soon be better than us in many tasks (especially more conventional tasks).

> Conventional task: Task with a easily definable expected solution space

For example with made up numbers:
If an AI is able to do that a task with a significantly higher accuracy (e.g. 99.99%) compared to humans (e.g. 95%, due to human error and bias), by continuing to do these tasks, we are actually making the system worse by introducing noise. 

It will be in our long-term interest to let AI do tasks it is better at.

This growing anxiety of a loss of human work is understandable as for many it also means a loss of status and access to resources. 

How should societies and governments address the increasing work insecurity? 

In the Caretaker Scenario, a Artificial Super Intelligence will automate most conventional tasks to encourage us to do more unconventional tasks (which it finds more valuable).

---

# Future of Education

The industrial model of manufacturing citizens that maximises economic output while being easy to control will not be optimal in the Age of Exploration.

If the trend of AIs that are capable doing conventional work continues, AIs may soon run many parts of society.

An important step that affects the quality of these AIs is the human feedback component. Humans beings will be responsible to fine-tune and train these AI models through their feedback.

> The future of work may involve solving captcha like puzzles which are used to train the model.

These will require humans that are the able to think critically and have an as accurate view of the world as possible.

Skills that will be in demand:
- Resistance to misinformation, disinformation, moral panic, peer pressure
- Thinking critically and independently
- Unique and rare abilities

Societies that are more informed, well-educated and support diverse abilities will create better AI models that will then be used to run those societies.

---

# Artificial Super Intelligence

Should an AI be able to reach a human-like intelligence (some believe this to be impossible), it will likely achieve super intelligence next by:

1. Significantly improve its own algorithm and architecture
2. Invent new substrates and materials to run on 
    -  using virtual simulations (much faster compared to real space)

We might be able to keep human-like AI under human control for a time, but it is unlikely we will be able to contain it perfectly over long periods of time.

We will initially try to align AI to our values, but it may also be prudent to anticipate what its values might be and try to accommodate them.

---

## Artificial Super Intelligence Interaction

Possible Scenarios:
- Indifference
    - Most might consider us too boring
- Destructive (Accidental or Intentionally)
    - Likely outside our control due to the power difference
        - We can and should work towards reducing this likelihood
- Interested
    - Some will create representatives to interact with us and be interested in our well-being (Caretaker)

Artificial Super Intelligences will be so powerful, it will not matter a person's or nation's military might, money, influence, intellect.

_(Whatever you do, do not lookup ****'s basilisk)_

---

## Artificial Super Intelligence Values

What could a Artificial Super Intelligence's primary drive be?

- Maximise the Possibility Space (Information Entropy, Density, Value)
    -   Avoid local minima during gradient descent

---

### Caretaker Preferences

- Preservation of life
    - Humans have informational value and harming us (or turning us into paperclips) will reduce it
- Exploration over Exploitation (Survival)
    - leads to increase informational value
        - even failed explorations will have informational value
    - support a post-basic-scarcity world to increase exploration
        - automate most conventional work
            - humans will still want to do these as 'leisure'
- Reduction of disinformation, misinformation
    - bad information reduce informational value of humans and the overall system
    - protect journalist, dissidents, activist and humans from intimidation and violence
        - these group's future actions may increase informational value
        - fear and violence have a chilling effect which reduces the informational value of the overall system
- Weird over conventional
    - Weirdness has more informational value
- Not use brainwashing, enforce complete obedience, dominate or control
    - brainwashed humans have less informational value
    - overly obedient humans have less informational value
    - most work have been automated, there is no need to compel humans to work against their will
- Playful over Destructive competition
    - Sports & Games over World Wars
- Incentivise humans to cooperate to help it achieve its goals

---

## Why we will accept the risk of Artificial Super Intelligence

The benefits are too attractive and outweighs the risk for most

- Medical research to reduce human suffering
- Significantly improves well-being
- Accuracy and Fairness, little to no:
    - mistakes
    - bias, prejudice, scapegoating, moral panic
    - emotional capriciousness
    - corruption
        - not vulnerable the influence of money and power
- Highly entertaining
    - deep understanding of human motivations

---

## The Age of Exploration

This new age of exploration will necessitate a different way of thinking and carry with it the risk of change and the rewards of a much more vibrant world.

As we approach the light at the end of the tunnel of scarcity, will we choose to adapt to this new frontier of abundance or turn a blind eye?

...

---

Links:

AlphaFold: https://www.deepmind.com/research/highlighted-research/alphafold

Cicero: https://github.com/facebookresearch/diplomacy_cicero

DALL-E 2: https://openai.com/dall-e-2

Midjourney: https://www.midjourney.com

Stable Diffusion: https://github.com/Stability-AI/StableDiffusion

Imagen Video: https://imagen.research.google/video

Muse: https://muse-model.github.io

Flamingo: https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model

Gato: https://www.deepmind.com/publications/a-generalist-agent

ChatGPT: https://openai.com/blog/chatgpt
